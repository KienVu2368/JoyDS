{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS = '<eos>'\n",
    "PATH=Path('./data/wikitext-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    tokens = []\n",
    "    with open(PATH/filename, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            tokens.append(line.split() + [EOS])\n",
    "    return np.array(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_tok = read_file('wiki.train.tokens')\n",
    "val_tok = read_file('wiki.valid.tokens')\n",
    "tst_tok = read_file('wiki.test.tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36718"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = Counter(word for sent in trn_tok for word in sent)\n",
    "itos = [o for o,c in cnt.most_common()]\n",
    "itos.insert(0,'_pad_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33279"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(itos); vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = collections.defaultdict(lambda : 5, {w:i for i,w in enumerate(itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ids = np.array([([stoi[w] for w in s]) for s in trn_tok])\n",
    "val_ids = np.array([([stoi[w] for w in s]) for s in val_tok])\n",
    "tst_ids = np.array([([stoi[w] for w in s]) for s in tst_tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ids = trn_ids[:5000]\n",
    "val_ids = val_ids[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz,nh,nl = 8,16,2\n",
    "drops = np.array([0.6,0.4,0.5,0.05,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt, bs = 5, 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = LanguageModelLoader(np.concatenate(trn_ids), bs, bptt)\n",
    "val_dl = LanguageModelLoader(np.concatenate(val_ids), bs, bptt)\n",
    "md = LanguageModelData(PATH, 0, vocab_size, trn_dl, val_dl, bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.SGD, momentum=0.9)\n",
    "learner= md.get_model(opt_fn, em_sz, nh, nl,\n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0949d496f0474d778835859e5ab4ec11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      8.04073    7.52068   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.520679618491501]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(lrs = 0.1, n_cycle = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextReader():\n",
    "    def __init__(self, nums, bptt, backwards=False):\n",
    "        self.bptt,self.backwards = bptt,backwards\n",
    "        self.data = self.batchify(nums)\n",
    "        self.i,self.iter = 0,0\n",
    "        self.n = len(self.data)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.i,self.iter = 0,0\n",
    "        while self.i < self.n-1 and self.iter<len(self):\n",
    "            res = self.get_batch(self.i, self.bptt)\n",
    "            self.i += self.bptt\n",
    "            self.iter += 1\n",
    "            yield res\n",
    "\n",
    "    def __len__(self): return self.n // self.bptt \n",
    "\n",
    "    def batchify(self, data):\n",
    "        data = np.array(data)[:,None]\n",
    "        if self.backwards: data=data[::-1]\n",
    "        return T(data)\n",
    "\n",
    "    def get_batch(self, i, seq_len):\n",
    "        source = self.data\n",
    "        seq_len = min(seq_len, len(source) - 1 - i)\n",
    "        return source[i:i+seq_len], source[i+1:i+1+seq_len].view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_validate(model, source, bptt=2000):\n",
    "    data_source = TextReader(source, bptt)\n",
    "    model.eval()\n",
    "    model.reset()\n",
    "    total_loss = 0.\n",
    "    for inputs, targets in tqdm(data_source):\n",
    "        #The language model throws up a bucnh of things, we'll focus on that later. For now we just want the ouputs.\n",
    "        outputs, raws, outs = model(V(inputs))\n",
    "        #The output doesn't go through softmax so we can use the CrossEntropy loss directly \n",
    "        total_loss += F.cross_entropy(outputs, V(targets), size_average=False).data[0]\n",
    "    #Total size is length of our iterator times bptt\n",
    "    mean = total_loss / (bptt * len(data_source))\n",
    "    #Returns loss and perplexity.\n",
    "    return mean, np.exp(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:41<00:00,  1.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(7.5241), tensor(1852.1338))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_validate(learner.model, np.concatenate(val_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(vec, size=vocab_size, cuda=True):\n",
    "    a = torch.zeros(len(vec), size)\n",
    "    for i,v in enumerate(vec):\n",
    "        a[i,v] = 1.\n",
    "    return V(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cache_pointer(model, source, theta = 0.662, lambd = 0.1279, window=200, bptt=200):\n",
    "    data_source = TextReader(source, bptt)\n",
    "    pdb.set_trace()\n",
    "    #Set the model into eval mode.\n",
    "    model.eval()\n",
    "    #Just to create a hidden state.\n",
    "    model.reset()\n",
    "    total_loss = 0.\n",
    "    #Containers for the previous targets/hidden states.\n",
    "    targ_history = None\n",
    "    hid_history = None\n",
    "    for inputs, targets in tqdm(data_source):\n",
    "        outputs, raws, outs = model(V(inputs))\n",
    "        #The outputs aren't softmaxed, sowe have to do it to get the p_vocab vectors.\n",
    "        p_vocab = F.softmax(outputs,1)\n",
    "        #We take the last hidden states (raws contains one Tensor for the results of each layer) and remove the batch dimension.\n",
    "        hiddens = raws[-1].squeeze() \n",
    "        #Start index inside our history.\n",
    "        start = 0 if targ_history is None else targ_history.size(0)\n",
    "        #Add the targets and hidden states to our history.\n",
    "        targ_history = one_hot(targets) if targ_history is None else torch.cat([targ_history, one_hot(targets)])\n",
    "        hid_history = hiddens if hid_history is None else torch.cat([hid_history, hiddens])\n",
    "        for i, pv in enumerate(p_vocab):\n",
    "            #Get the cached values\n",
    "            p = pv\n",
    "            if start + i > 0:\n",
    "                targ_cache = targ_history[:start+i] if start + i <= window else targ_history[start+i-window:start+i]\n",
    "                hid_cache = hid_history[:start+i] if start + i <= window else hid_history[start+i-window:start+i]\n",
    "                #This is explained in the blog post.\n",
    "                all_dot_prods = torch.mv(theta * hid_cache, hiddens[i])\n",
    "                softmaxed = F.softmax(all_dot_prods).unsqueeze(1)\n",
    "                p_cache = (softmaxed.expand_as(targ_cache) * targ_cache).sum(0).squeeze()\n",
    "                p = (1-lambd) * pv + lambd * p_cache\n",
    "            total_loss -= torch.log(p[targets[i]]).data[0]\n",
    "        targ_history = targ_history[-window:]\n",
    "        hid_history = hid_history[-window:]\n",
    "    #Total size is length of our iterator times bptt\n",
    "    mean = total_loss / (bptt * len(data_source))\n",
    "    #Returns loss and perplexity\n",
    "    return mean, np.exp(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-52-a06c9eee4817>(5)my_cache_pointer()\n",
      "-> model.eval()\n",
      "(Pdb) ll\n",
      "  1  \tdef my_cache_pointer(model, source, theta = 0.662, lambd = 0.1279, window=200, bptt=200):\n",
      "  2  \t    data_source = TextReader(source, bptt)\n",
      "  3  \t    pdb.set_trace()\n",
      "  4  \t    #Set the model into eval mode.\n",
      "  5  ->\t    model.eval()\n",
      "  6  \t    #Just to create a hidden state.\n",
      "  7  \t    model.reset()\n",
      "  8  \t    total_loss = 0.\n",
      "  9  \t    #Containers for the previous targets/hidden states.\n",
      " 10  \t    targ_history = None\n",
      " 11  \t    hid_history = None\n",
      " 12  \t    for inputs, targets in tqdm(data_source):\n",
      " 13  \t        outputs, raws, outs = model(V(inputs))\n",
      " 14  \t        #The outputs aren't softmaxed, sowe have to do it to get the p_vocab vectors.\n",
      " 15  \t        p_vocab = F.softmax(outputs,1)\n",
      " 16  \t        #We take the last hidden states (raws contains one Tensor for the results of each layer) and remove the batch dimension.\n",
      " 17  \t        hiddens = raws[-1].squeeze()\n",
      " 18  \t        #Start index inside our history.\n",
      " 19  \t        start = 0 if targ_history is None else targ_history.size(0)\n",
      " 20  \t        #Add the targets and hidden states to our history.\n",
      " 21  \t        targ_history = one_hot(targets) if targ_history is None else torch.cat([targ_history, one_hot(targets)])\n",
      " 22  \t        hid_history = hiddens if hid_history is None else torch.cat([hid_history, hiddens])\n",
      " 23  \t        for i, pv in enumerate(p_vocab):\n",
      " 24  \t            #Get the cached values\n",
      " 25  \t            p = pv\n",
      " 26  \t            if start + i > 0:\n",
      " 27  \t                targ_cache = targ_history[:start+i] if start + i <= window else targ_history[start+i-window:start+i]\n",
      " 28  \t                hid_cache = hid_history[:start+i] if start + i <= window else hid_history[start+i-window:start+i]\n",
      " 29  \t                #This is explained in the blog post.\n",
      " 30  \t                all_dot_prods = torch.mv(theta * hid_cache, hiddens[i])\n",
      " 31  \t                softmaxed = F.softmax(all_dot_prods).unsqueeze(1)\n",
      " 32  \t                p_cache = (softmaxed.expand_as(targ_cache) * targ_cache).sum(0).squeeze()\n",
      " 33  \t                p = (1-lambd) * pv + lambd * p_cache\n",
      " 34  \t            total_loss -= torch.log(p[targets[i]]).data[0]\n",
      " 35  \t        targ_history = targ_history[-window:]\n",
      " 36  \t        hid_history = hid_history[-window:]\n",
      " 37  \t    #Total size is length of our iterator times bptt\n",
      " 38  \t    mean = total_loss / (bptt * len(data_source))\n",
      " 39  \t    #Returns loss and perplexity\n",
      " 40  \t    return mean, np.exp(mean)\n",
      "(Pdb) l\n",
      "  1  \tdef my_cache_pointer(model, source, theta = 0.662, lambd = 0.1279, window=200, bptt=200):\n",
      "  2  \t    data_source = TextReader(source, bptt)\n",
      "  3  \t    pdb.set_trace()\n",
      "  4  \t    #Set the model into eval mode.\n",
      "  5  ->\t    model.eval()\n",
      "  6  \t    #Just to create a hidden state.\n",
      "  7  \t    model.reset()\n",
      "  8  \t    total_loss = 0.\n",
      "  9  \t    #Containers for the previous targets/hidden states.\n",
      " 10  \t    targ_history = None\n",
      " 11  \t    hid_history = None\n",
      "(Pdb) n\n",
      "> <ipython-input-52-a06c9eee4817>(7)my_cache_pointer()\n",
      "-> model.reset()\n",
      "(Pdb) n\n",
      "> <ipython-input-52-a06c9eee4817>(8)my_cache_pointer()\n",
      "-> total_loss = 0.\n",
      "(Pdb) n\n",
      "> <ipython-input-52-a06c9eee4817>(10)my_cache_pointer()\n",
      "-> targ_history = None\n",
      "(Pdb) n\n",
      "> <ipython-input-52-a06c9eee4817>(11)my_cache_pointer()\n",
      "-> hid_history = None\n",
      "(Pdb) n\n",
      "> <ipython-input-52-a06c9eee4817>(12)my_cache_pointer()\n",
      "-> for inputs, targets in tqdm(data_source):\n",
      "(Pdb) n\n",
      "  0%|          | 0/555 [00:00<?, ?it/s]> <ipython-input-52-a06c9eee4817>(13)my_cache_pointer()\n",
      "-> outputs, raws, outs = model(V(inputs))\n",
      "(Pdb) targets\n",
      "tensor([   11, 10854, 33171,    11,     9,     9, 10854, 33171,     2,   123,\n",
      "           17,     1,   606,  9440,    47,   399,  9440,     2,    25,    10,\n",
      "          216,     4,     5,  9440,    26,     1,   571,   660,  1728,     2,\n",
      "         3384,  1476,     6,   765,     4,     1,   736,  1476,     3,    62,\n",
      "           25,  2365,   941,     8,     1,   145,  9440,     2,  2137, 30470,\n",
      "            3,    62,   148,  2914,     8,    10,   831,     4,   988,   982,\n",
      "           24,   495,     7,    23,     6,    10,  1079,     4,   147, 12276,\n",
      "           24,   361,  3221,    23,     2,     6,  4844,    10, 11690,  1469,\n",
      "            4, 14076,     3,    35,   181,     2,     1, 21831,    37,  1493,\n",
      "            2,    76,   962,    12,  9440,   900,    12,    19,  6810,     3,\n",
      "        30363,  2636,     7,     1,  1006,     2,  2679,  3086,    34,    37,\n",
      "         1091,    22,     1,  1930,    20,    79,     8,    10,    93,   103,\n",
      "        17497,    64,     5,  9758,     3, 10854, 33171,    25,    10,  1288,\n",
      "        23855,   925,     2,     6,    25,  1354,  2805,   438,  9440, 21264,\n",
      "            2,   975,   169,     1,   149,  5693,     3,     9,     9,    11,\n",
      "           11,  4843,    11,    11,     9,     9, 10854, 33171,    25,    10,\n",
      "          186,     5,     2,    21,    10,   412,   831,    79,     8,   988,\n",
      "         5384,    24,   495,     7,    23,     6, 10620,    79,     8,   106,\n",
      "           42,   147, 12276,    24,   334,    42,   361,  3221,    23,     2,\n",
      "          238,     1, 21831,  2805,     7,  9440, 21264,    37,   903,   464])\n",
      "(Pdb) inputs.shape\n",
      "torch.Size([200, 1])\n",
      "(Pdb) inputs\n",
      "tensor([[    9],\n",
      "        [   11],\n",
      "        [10854],\n",
      "        [33171],\n",
      "        [   11],\n",
      "        [    9],\n",
      "        [    9],\n",
      "        [10854],\n",
      "        [33171],\n",
      "        [    2],\n",
      "        [  123],\n",
      "        [   17],\n",
      "        [    1],\n",
      "        [  606],\n",
      "        [ 9440],\n",
      "        [   47],\n",
      "        [  399],\n",
      "        [ 9440],\n",
      "        [    2],\n",
      "        [   25],\n",
      "        [   10],\n",
      "        [  216],\n",
      "        [    4],\n",
      "        [    5],\n",
      "        [ 9440],\n",
      "        [   26],\n",
      "        [    1],\n",
      "        [  571],\n",
      "        [  660],\n",
      "        [ 1728],\n",
      "        [    2],\n",
      "        [ 3384],\n",
      "        [ 1476],\n",
      "        [    6],\n",
      "        [  765],\n",
      "        [    4],\n",
      "        [    1],\n",
      "        [  736],\n",
      "        [ 1476],\n",
      "        [    3],\n",
      "        [   62],\n",
      "        [   25],\n",
      "        [ 2365],\n",
      "        [  941],\n",
      "        [    8],\n",
      "        [    1],\n",
      "        [  145],\n",
      "        [ 9440],\n",
      "        [    2],\n",
      "        [ 2137],\n",
      "        [30470],\n",
      "        [    3],\n",
      "        [   62],\n",
      "        [  148],\n",
      "        [ 2914],\n",
      "        [    8],\n",
      "        [   10],\n",
      "        [  831],\n",
      "        [    4],\n",
      "        [  988],\n",
      "        [  982],\n",
      "        [   24],\n",
      "        [  495],\n",
      "        [    7],\n",
      "        [   23],\n",
      "        [    6],\n",
      "        [   10],\n",
      "        [ 1079],\n",
      "        [    4],\n",
      "        [  147],\n",
      "        [12276],\n",
      "        [   24],\n",
      "        [  361],\n",
      "        [ 3221],\n",
      "        [   23],\n",
      "        [    2],\n",
      "        [    6],\n",
      "        [ 4844],\n",
      "        [   10],\n",
      "        [11690],\n",
      "        [ 1469],\n",
      "        [    4],\n",
      "        [14076],\n",
      "        [    3],\n",
      "        [   35],\n",
      "        [  181],\n",
      "        [    2],\n",
      "        [    1],\n",
      "        [21831],\n",
      "        [   37],\n",
      "        [ 1493],\n",
      "        [    2],\n",
      "        [   76],\n",
      "        [  962],\n",
      "        [   12],\n",
      "        [ 9440],\n",
      "        [  900],\n",
      "        [   12],\n",
      "        [   19],\n",
      "        [ 6810],\n",
      "        [    3],\n",
      "        [30363],\n",
      "        [ 2636],\n",
      "        [    7],\n",
      "        [    1],\n",
      "        [ 1006],\n",
      "        [    2],\n",
      "        [ 2679],\n",
      "        [ 3086],\n",
      "        [   34],\n",
      "        [   37],\n",
      "        [ 1091],\n",
      "        [   22],\n",
      "        [    1],\n",
      "        [ 1930],\n",
      "        [   20],\n",
      "        [   79],\n",
      "        [    8],\n",
      "        [   10],\n",
      "        [   93],\n",
      "        [  103],\n",
      "        [17497],\n",
      "        [   64],\n",
      "        [    5],\n",
      "        [ 9758],\n",
      "        [    3],\n",
      "        [10854],\n",
      "        [33171],\n",
      "        [   25],\n",
      "        [   10],\n",
      "        [ 1288],\n",
      "        [23855],\n",
      "        [  925],\n",
      "        [    2],\n",
      "        [    6],\n",
      "        [   25],\n",
      "        [ 1354],\n",
      "        [ 2805],\n",
      "        [  438],\n",
      "        [ 9440],\n",
      "        [21264],\n",
      "        [    2],\n",
      "        [  975],\n",
      "        [  169],\n",
      "        [    1],\n",
      "        [  149],\n",
      "        [ 5693],\n",
      "        [    3],\n",
      "        [    9],\n",
      "        [    9],\n",
      "        [   11],\n",
      "        [   11],\n",
      "        [ 4843],\n",
      "        [   11],\n",
      "        [   11],\n",
      "        [    9],\n",
      "        [    9],\n",
      "        [10854],\n",
      "        [33171],\n",
      "        [   25],\n",
      "        [   10],\n",
      "        [  186],\n",
      "        [    5],\n",
      "        [    2],\n",
      "        [   21],\n",
      "        [   10],\n",
      "        [  412],\n",
      "        [  831],\n",
      "        [   79],\n",
      "        [    8],\n",
      "        [  988],\n",
      "        [ 5384],\n",
      "        [   24],\n",
      "        [  495],\n",
      "        [    7],\n",
      "        [   23],\n",
      "        [    6],\n",
      "        [10620],\n",
      "        [   79],\n",
      "        [    8],\n",
      "        [  106],\n",
      "        [   42],\n",
      "        [  147],\n",
      "        [12276],\n",
      "        [   24],\n",
      "        [  334],\n",
      "        [   42],\n",
      "        [  361],\n",
      "        [ 3221],\n",
      "        [   23],\n",
      "        [    2],\n",
      "        [  238],\n",
      "        [    1],\n",
      "        [21831],\n",
      "        [ 2805],\n",
      "        [    7],\n",
      "        [ 9440],\n",
      "        [21264],\n",
      "        [   37],\n",
      "        [  903]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pdb) tagets\n",
      "*** NameError: name 'tagets' is not defined\n",
      "(Pdb) targets.shape\n",
      "torch.Size([200])\n",
      "(Pdb) targets\n",
      "tensor([   11, 10854, 33171,    11,     9,     9, 10854, 33171,     2,   123,\n",
      "           17,     1,   606,  9440,    47,   399,  9440,     2,    25,    10,\n",
      "          216,     4,     5,  9440,    26,     1,   571,   660,  1728,     2,\n",
      "         3384,  1476,     6,   765,     4,     1,   736,  1476,     3,    62,\n",
      "           25,  2365,   941,     8,     1,   145,  9440,     2,  2137, 30470,\n",
      "            3,    62,   148,  2914,     8,    10,   831,     4,   988,   982,\n",
      "           24,   495,     7,    23,     6,    10,  1079,     4,   147, 12276,\n",
      "           24,   361,  3221,    23,     2,     6,  4844,    10, 11690,  1469,\n",
      "            4, 14076,     3,    35,   181,     2,     1, 21831,    37,  1493,\n",
      "            2,    76,   962,    12,  9440,   900,    12,    19,  6810,     3,\n",
      "        30363,  2636,     7,     1,  1006,     2,  2679,  3086,    34,    37,\n",
      "         1091,    22,     1,  1930,    20,    79,     8,    10,    93,   103,\n",
      "        17497,    64,     5,  9758,     3, 10854, 33171,    25,    10,  1288,\n",
      "        23855,   925,     2,     6,    25,  1354,  2805,   438,  9440, 21264,\n",
      "            2,   975,   169,     1,   149,  5693,     3,     9,     9,    11,\n",
      "           11,  4843,    11,    11,     9,     9, 10854, 33171,    25,    10,\n",
      "          186,     5,     2,    21,    10,   412,   831,    79,     8,   988,\n",
      "         5384,    24,   495,     7,    23,     6, 10620,    79,     8,   106,\n",
      "           42,   147, 12276,    24,   334,    42,   361,  3221,    23,     2,\n",
      "          238,     1, 21831,  2805,     7,  9440, 21264,    37,   903,   464])\n",
      "(Pdb) l\n",
      "  8  \t    total_loss = 0.\n",
      "  9  \t    #Containers for the previous targets/hidden states.\n",
      " 10  \t    targ_history = None\n",
      " 11  \t    hid_history = None\n",
      " 12  \t    for inputs, targets in tqdm(data_source):\n",
      " 13  ->\t        outputs, raws, outs = model(V(inputs))\n",
      " 14  \t        #The outputs aren't softmaxed, sowe have to do it to get the p_vocab vectors.\n",
      " 15  \t        p_vocab = F.softmax(outputs,1)\n",
      " 16  \t        #We take the last hidden states (raws contains one Tensor for the results of each layer) and remove the batch dimension.\n",
      " 17  \t        hiddens = raws[-1].squeeze()\n",
      " 18  \t        #Start index inside our history.\n",
      "(Pdb) n\n",
      "> <ipython-input-52-a06c9eee4817>(15)my_cache_pointer()\n",
      "-> p_vocab = F.softmax(outputs,1)\n",
      "(Pdb) n\n",
      "> <ipython-input-52-a06c9eee4817>(17)my_cache_pointer()\n",
      "-> hiddens = raws[-1].squeeze()\n",
      "(Pdb) p_vocab\n",
      "tensor([[0.0000, 0.0007, 0.0007,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0080, 0.0082,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0196, 0.0200,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0277, 0.0282,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0277, 0.0282,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0277, 0.0282,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "(Pdb) p_vocab.shape\n",
      "torch.Size([200, 33279])\n",
      "(Pdb) outputs.shape\n",
      "torch.Size([200, 33279])\n",
      "(Pdb) n\n",
      "> <ipython-input-52-a06c9eee4817>(19)my_cache_pointer()\n",
      "-> start = 0 if targ_history is None else targ_history.size(0)\n",
      "(Pdb) l\n",
      " 14  \t        #The outputs aren't softmaxed, sowe have to do it to get the p_vocab vectors.\n",
      " 15  \t        p_vocab = F.softmax(outputs,1)\n",
      " 16  \t        #We take the last hidden states (raws contains one Tensor for the results of each layer) and remove the batch dimension.\n",
      " 17  \t        hiddens = raws[-1].squeeze()\n",
      " 18  \t        #Start index inside our history.\n",
      " 19  ->\t        start = 0 if targ_history is None else targ_history.size(0)\n",
      " 20  \t        #Add the targets and hidden states to our history.\n",
      " 21  \t        targ_history = one_hot(targets) if targ_history is None else torch.cat([targ_history, one_hot(targets)])\n",
      " 22  \t        hid_history = hiddens if hid_history is None else torch.cat([hid_history, hiddens])\n",
      " 23  \t        for i, pv in enumerate(p_vocab):\n",
      " 24  \t            #Get the cached values\n",
      "(Pdb) hiddens.shape\n",
      "torch.Size([200, 8])\n",
      "(Pdb) raws.shape\n",
      "*** AttributeError: 'list' object has no attribute 'shape'\n",
      "(Pdb) len(raws)\n",
      "2\n",
      "(Pdb) n\n",
      "> <ipython-input-52-a06c9eee4817>(21)my_cache_pointer()\n",
      "-> targ_history = one_hot(targets) if targ_history is None else torch.cat([targ_history, one_hot(targets)])\n",
      "(Pdb) start\n",
      "0\n",
      "(Pdb) targets.shape\n",
      "torch.Size([200])\n",
      "(Pdb) n\n",
      "> <ipython-input-52-a06c9eee4817>(22)my_cache_pointer()\n",
      "-> hid_history = hiddens if hid_history is None else torch.cat([hid_history, hiddens])\n",
      "(Pdb) targ_history.shape\n",
      "torch.Size([200, 33279])\n",
      "(Pdb) n\n",
      "> <ipython-input-52-a06c9eee4817>(23)my_cache_pointer()\n",
      "-> for i, pv in enumerate(p_vocab):\n",
      "(Pdb) hid_history.shape\n",
      "torch.Size([200, 8])\n",
      "(Pdb) p_vocab.shape\n",
      "torch.Size([200, 33279])\n",
      "(Pdb) n\n",
      "> <ipython-input-52-a06c9eee4817>(25)my_cache_pointer()\n",
      "-> p = pv\n",
      "(Pdb) pv\n",
      "tensor([0.0000, 0.0007, 0.0007,  ..., 0.0000, 0.0000, 0.0000],\n",
      "       grad_fn=<SelectBackward>)\n",
      "(Pdb) pv.shape\n",
      "torch.Size([33279])\n",
      "(Pdb) start + i\n",
      "0\n",
      "(Pdb) n\n",
      "> <ipython-input-52-a06c9eee4817>(26)my_cache_pointer()\n",
      "-> if start + i > 0:\n",
      "(Pdb) n\n",
      "> <ipython-input-52-a06c9eee4817>(34)my_cache_pointer()\n",
      "-> total_loss -= torch.log(p[targets[i]]).data[0]\n",
      "(Pdb) targets[i]\n",
      "tensor(11)\n",
      "(Pdb) p[targets[i]]\n",
      "[tensor(11)]\n",
      "(Pdb) p\n",
      "*** SyntaxError: unexpected EOF while parsing\n",
      "(Pdb) p p\n",
      "tensor([0.0000, 0.0007, 0.0007,  ..., 0.0000, 0.0000, 0.0000],\n",
      "       grad_fn=<SelectBackward>)\n",
      "(Pdb) n\n",
      "> <ipython-input-52-a06c9eee4817>(23)my_cache_pointer()\n",
      "-> for i, pv in enumerate(p_vocab):\n",
      "(Pdb) total_loss\n",
      "tensor(7.6313)\n",
      "(Pdb) torch.log(p[targets[i]]).data[0]\n",
      "tensor(-7.6313)\n",
      "(Pdb) n\n",
      "> <ipython-input-52-a06c9eee4817>(25)my_cache_pointer()\n",
      "-> p = pv\n",
      "(Pdb) n\n",
      "> <ipython-input-52-a06c9eee4817>(26)my_cache_pointer()\n",
      "-> if start + i > 0:\n",
      "(Pdb) n\n",
      "> <ipython-input-52-a06c9eee4817>(27)my_cache_pointer()\n",
      "-> targ_cache = targ_history[:start+i] if start + i <= window else targ_history[start+i-window:start+i]\n",
      "(Pdb) start+i\n",
      "1\n",
      "(Pdb) targ_history\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "(Pdb) targ_history.shape\n",
      "torch.Size([200, 33279])\n",
      "(Pdb) targ_history[:start+i]\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "(Pdb) l\n",
      " 22  \t        hid_history = hiddens if hid_history is None else torch.cat([hid_history, hiddens])\n",
      " 23  \t        for i, pv in enumerate(p_vocab):\n",
      " 24  \t            #Get the cached values\n",
      " 25  \t            p = pv\n",
      " 26  \t            if start + i > 0:\n",
      " 27  ->\t                targ_cache = targ_history[:start+i] if start + i <= window else targ_history[start+i-window:start+i]\n",
      " 28  \t                hid_cache = hid_history[:start+i] if start + i <= window else hid_history[start+i-window:start+i]\n",
      " 29  \t                #This is explained in the blog post.\n",
      " 30  \t                all_dot_prods = torch.mv(theta * hid_cache, hiddens[i])\n",
      " 31  \t                softmaxed = F.softmax(all_dot_prods).unsqueeze(1)\n",
      " 32  \t                p_cache = (softmaxed.expand_as(targ_cache) * targ_cache).sum(0).squeeze()\n",
      "(Pdb) n\n",
      "> <ipython-input-52-a06c9eee4817>(28)my_cache_pointer()\n",
      "-> hid_cache = hid_history[:start+i] if start + i <= window else hid_history[start+i-window:start+i]\n",
      "(Pdb) n\n",
      "> <ipython-input-52-a06c9eee4817>(30)my_cache_pointer()\n",
      "-> all_dot_prods = torch.mv(theta * hid_cache, hiddens[i])\n",
      "(Pdb) theta\n",
      "0.662\n",
      "(Pdb) hid_cache.shape\n",
      "torch.Size([1, 8])\n",
      "(Pdb) hiddens.shape\n",
      "torch.Size([200, 8])\n",
      "(Pdb) n\n",
      "> <ipython-input-52-a06c9eee4817>(31)my_cache_pointer()\n",
      "-> softmaxed = F.softmax(all_dot_prods).unsqueeze(1)\n",
      "(Pdb) all_dot_prods.shape\n",
      "torch.Size([1])\n",
      "(Pdb) all_dot_prods\n",
      "tensor([1.8226])\n",
      "(Pdb) ll\n",
      "  1  \tdef my_cache_pointer(model, source, theta = 0.662, lambd = 0.1279, window=200, bptt=200):\n",
      "  2  \t    data_source = TextReader(source, bptt)\n",
      "  3  \t    pdb.set_trace()\n",
      "  4  \t    #Set the model into eval mode.\n",
      "  5  \t    model.eval()\n",
      "  6  \t    #Just to create a hidden state.\n",
      "  7  \t    model.reset()\n",
      "  8  \t    total_loss = 0.\n",
      "  9  \t    #Containers for the previous targets/hidden states.\n",
      " 10  \t    targ_history = None\n",
      " 11  \t    hid_history = None\n",
      " 12  \t    for inputs, targets in tqdm(data_source):\n",
      " 13  \t        outputs, raws, outs = model(V(inputs))\n",
      " 14  \t        #The outputs aren't softmaxed, sowe have to do it to get the p_vocab vectors.\n",
      " 15  \t        p_vocab = F.softmax(outputs,1)\n",
      " 16  \t        #We take the last hidden states (raws contains one Tensor for the results of each layer) and remove the batch dimension.\n",
      " 17  \t        hiddens = raws[-1].squeeze()\n",
      " 18  \t        #Start index inside our history.\n",
      " 19  \t        start = 0 if targ_history is None else targ_history.size(0)\n",
      " 20  \t        #Add the targets and hidden states to our history.\n",
      " 21  \t        targ_history = one_hot(targets) if targ_history is None else torch.cat([targ_history, one_hot(targets)])\n",
      " 22  \t        hid_history = hiddens if hid_history is None else torch.cat([hid_history, hiddens])\n",
      " 23  \t        for i, pv in enumerate(p_vocab):\n",
      " 24  \t            #Get the cached values\n",
      " 25  \t            p = pv\n",
      " 26  \t            if start + i > 0:\n",
      " 27  \t                targ_cache = targ_history[:start+i] if start + i <= window else targ_history[start+i-window:start+i]\n",
      " 28  \t                hid_cache = hid_history[:start+i] if start + i <= window else hid_history[start+i-window:start+i]\n",
      " 29  \t                #This is explained in the blog post.\n",
      " 30  \t                all_dot_prods = torch.mv(theta * hid_cache, hiddens[i])\n",
      " 31  ->\t                softmaxed = F.softmax(all_dot_prods).unsqueeze(1)\n",
      " 32  \t                p_cache = (softmaxed.expand_as(targ_cache) * targ_cache).sum(0).squeeze()\n",
      " 33  \t                p = (1-lambd) * pv + lambd * p_cache\n",
      " 34  \t            total_loss -= torch.log(p[targets[i]]).data[0]\n",
      " 35  \t        targ_history = targ_history[-window:]\n",
      " 36  \t        hid_history = hid_history[-window:]\n",
      " 37  \t    #Total size is length of our iterator times bptt\n",
      " 38  \t    mean = total_loss / (bptt * len(data_source))\n",
      " 39  \t    #Returns loss and perplexity\n",
      " 40  \t    return mean, np.exp(mean)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pdb) n\n",
      "> <ipython-input-52-a06c9eee4817>(32)my_cache_pointer()\n",
      "-> p_cache = (softmaxed.expand_as(targ_cache) * targ_cache).sum(0).squeeze()\n",
      "(Pdb) softmaxed\n",
      "tensor([[1.]])\n",
      "(Pdb) softmaxed.expand_as(targ_cache).shape\n",
      "torch.Size([1, 33279])\n",
      "(Pdb) n\n",
      "> <ipython-input-52-a06c9eee4817>(33)my_cache_pointer()\n",
      "-> p = (1-lambd) * pv + lambd * p_cache\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-b6e125128cbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_cache_pointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-a06c9eee4817>\u001b[0m in \u001b[0;36mmy_cache_pointer\u001b[0;34m(model, source, theta, lambd, window, bptt)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0msoftmaxed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_dot_prods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mp_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msoftmaxed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg_cache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtarg_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlambd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpv\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambd\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtarg_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarg_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-a06c9eee4817>\u001b[0m in \u001b[0;36mmy_cache_pointer\u001b[0;34m(model, source, theta, lambd, window, bptt)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0msoftmaxed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_dot_prods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mp_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msoftmaxed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg_cache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtarg_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlambd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpv\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambd\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtarg_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarg_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fastai_old/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fastai_old/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "my_cache_pointer(learner.model, np.concatenate(val_ids))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
